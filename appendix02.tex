\section{Derivation of the Student's {\it t}-likelihood function}\label{app:likelihood}

Here we derive, in detail, the form of the Student's {\it t}-likelihood given in Section~\ref{sec:likelihood}.
This derivation can, in part, be found in \citet{Dupuisthesis} and \citet{2005PhRvD..72j2002D}, but we correct a
slight error from those references.

If a stretch of data of length $m$ is assumed to consist of a signal
defined by a set of parameters $\vec{\theta}$ and Gaussian noise with zero mean and standard deviation
$\sigma$, then the standard deviation can be included as an unknown parameter in the likelihood function and
marginalised over. The likelihood can therefore be given by
\begin{equation}\label{eq:likesigma}
p(\mathbf{B}|\vec{\theta},I) = \int_0^{\infty} p(\mathbf{B},\sigma|\vec{\theta},I) \text{d}\sigma =
\int_0^{\infty} p(\mathbf{B}|\vec{\theta},\sigma,I)p(\sigma|I) \text{d}\sigma,
\end{equation}
where $p(\mathbf{B}|\vec{\theta},\sigma,I)$ is the likelihood function for the data given the unknown signal
parameters and the noise standard deviation, and $p(\sigma|I)$ is the prior on $\sigma$.

Given that the noise is assumed Gaussian the likelihood within the integral is given by
\begin{equation}\label{eq:likesigma2}
p(\mathbf{B}|\vec{\theta},\sigma,I) = \left(\frac{1}{2\pi\sigma^2}\right)^{m}
\exp{\left( -\frac{\sum_{k=1}^m|B_k-y(\vec{\theta})_k|^2}{2\sigma^2} \right)}.
\end{equation}
for our complex data $B$ and model $y$, where for a complex number $x$ we have used $|x|^2 =
\Re{(x)}^2+\Im{(x)}^2$, and the noise in the real and imaginary parts is assumed to have the same
distribution.

We chose a scale invariant prior on $\sigma$ of $p(\sigma|I) = 1/\sigma$, for which the marginalisation of
Eqn.~\ref{eq:likesigma} can be performed analytically as we will show.
Substituting this prior and Eqn.~\ref{eq:likesigma2} into Eqn.~\ref{eq:likesigma} we can begin the
integration with the substitution
\begin{equation}\label{eq:u}
u = \sqrt{\frac{\sum_{k=1}^m|B_k-y(\vec{\theta})_k|^2}{2\sigma^2}},
\end{equation}
giving
\begin{equation}\label{eq:du}
\left|\frac{\text{d}u}{\text{d}\sigma}\right| = \sqrt{\frac{\sum_{k=1}^m|B_k-y(\vec{\theta})_k|^2}{2}}\sigma^{-2}.
\end{equation}
Here we note that Eqn.~\ref{eq:du} is different from the equivalent Eqn.~2.28 in \citet{Dupuisthesis} by a
factor of two. Rearranging Eqns.~\ref{eq:u} and~\ref{eq:du}, and for simplicity using the substitution $X =
\sum_{k=1}^m |B_k-y(\vec{\theta})_k|^2$, gives
\begin{equation}
\sigma = \left(\frac{X}{2u^2}\right)^{1/2},
\end{equation}
and
\begin{align}
\text{d}\sigma = & \sigma^2 \left(\frac{2}{X}\right)^{1/2} \text{d}u
\nonumber \\
 = & \frac{X}{2u^2} \left(\frac{2}{X}\right)^{1/2} \text{d}u \nonumber \\
 = & 2^{-1/2} X^{1/2} u^{-2} \text{d}u.
\end{align}
Putting everything into Eqn.~\ref{eq:likesigma} gives
%\begin{widetext}
\begin{align}\label{eq:integral1}
p(\mathbf{B}|\vec{\theta})= & (2\pi)^{-m} \int_0^{\infty} 2^{(m+\frac{1}{2})}
X^{-(m+\frac{1}{2})} u^{2m+1} e^{-u^2} 2^{-1/2} X^{1/2} u^{-2} \text{d}u, \nonumber \\
 = & \pi^{-m} X^{-m} \int_0^{\infty} u^{2m-1} e^{-u^2} \text{d}u.
\end{align}
%\end{widetext}
The integral in Eqn.~\ref{eq:integral1} can then be performed by making the substitutions $x = u^2$ and $\text{d}x
= 2u\,\text{d}u$, giving
\begin{equation}
p(\mathbf{B}|\vec{\theta}) = \pi^{-m} X^{-m} \int_0^{\infty} \frac{1}{2} x^{m-1} e^{-x}
\text{d}x.
\end{equation}
This integral is the definition of the Gamma function
\begin{equation}
 \int_0^{\infty} x^{m-1} e^{-x} \text{d}x = \Gamma(m).
\end{equation}
For positive integers, Stirling's formula shows that the Gamma function is given by $\Gamma(n+1) = n!$, so our
likelihood becomes
\begin{equation}\label{eq:complex}
p(\mathbf{B}|\vec{\theta}) = \frac{(m-1)!}{2\pi^m} \left(\sum_{k=1}^m
|B_k-y(\vec{\theta})_k|^2\right)^{-m}.
\end{equation}
Note that, again, this differs from Eqn.~2.31 in \citet{Dupuisthesis} by some constant factors.

For our analysis the data is split into chunks for each of which the assumption of noise stationarity is
thought to be valid, but between chunks is thought to be invalid (see discussion in \S\ref{sec:splitting}). The joint likelihood of all data can be
obtained from the product of the likelihood for each chunk given by
\begin{equation}\label{eq:prod}
p(\mathbf{B}|\vec{\theta},I) = \prod_{j=1}^M \frac{(m_j-1)!}{2\pi^{m_j}}
\left(\sum_{k=k_0}^{k_0+(m_j-1)} |B_k-y(\vec{\theta})_k|^2\right)^{-m_j},
\end{equation}
where $M$ is the total number of independent data chunks with lengths $m_j$ and $k_0 = 1+\sum_{i=1}^{j}
m_{i-1}$ (with $m_0 = 0$) is the index of the first data point in each chunk.
