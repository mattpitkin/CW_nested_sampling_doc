\appendix

\section{Code usage}

Here we document the various command line options for the code and its use in a variety of situations. All the command
line options for \lppen, as shown with the \verb|--help| command, are given below.
\begin{lstlisting}[frame=single]
Usage: lalapps_pulsar_parameter_estimation_nested [options]

 --help              display this message
 --verbose           display all error messages
 --detectors         all IFOs with data to be analysed e.g. H1,H2 (delimited by commas) (if generating fake data these
                     should not be set)
 --par-file          pulsar parameter (.par) file (full path)
 --cor-file          pulsar TEMPO-fit parameter correlation matrix
 --input-files       full paths and file names for the data for each detector and model harmonic in the list (must be
                     in the same order) delimited by commas. These files can be gzipped. If not set you can generate
                     fake data (see --fake-data below)
 --sample-interval   (REAL8) the time interval bewteen samples (default to 60 s)
 --outfile           name of output data file (a HDF5 formated file with the extension '.hdf' or '.h5' [required])
 --output-chunks     Output lists of stationary chunks into which the data has been split
 --outXML            name of output XML file [not required]
 --chunk-min         (INT4) minimum stationary length of data to be used in the likelihood e.g. 5 mins
 --chunk-max         (INT4) maximum stationary length of data to be used in the likelihood e.g. 30 mins
 --time-bins         (INT4) no. of time bins in the time-psi lookup table
 --prior-file        file containing the parameters to search over and their upper and lower ranges
 --ephem-earth       Earth ephemeris file
 --ephem-sun         Sun ephemeris file
 --ephem-timecorr    Einstein delay time correction ephemeris file
 --harmonics         (CHAR) the signal model frequency harmonics that you want to use (delimited by commas). Currently
                     this can be either the 'triaxial' model for which you use 2 (the default value) or 1,2 for a
                     model with emission at both the rotation frequency and twice the rotation frequency.
 --biaxial           Set this if the waveform model parameters spcify a biaxial star
 --gaussian-like     Set this if a Gaussian likelihood is to be used. If the input file contains a column specifying
                     the noise standard deviation of the data then that will be used in the Gaussian likelihood
                     function, otherwise the noise variance will be calculated from the data.
 --nonGR             Set to allow non-GR polarisation modes and/or a variable speed of gravitational waves
 --randomise         Set this, with an INT seed, to randomise the data (through permutations of the time stamps) for
                     use in Monte-Carlo studies. NOTE: this will not work if using the code to create injections

 Nested sampling parameters:
 --Nlive             (INT4) no. of live points for nested sampling
 --Nmcmc             (INT4) no. of for MCMC used to find new live points (if not specified an  adaptive number of
                     points is used)
 --Nmcmcinitial      (INT4) no. of MCMC points to use in the initial resampling of the prior (default is to use
                     MAXMCMC)
 --Nruns             (INT4) no. of parallel runs
 --tolerance         (REAL8) tolerance of nested sampling integrator
 --randomseed        seed for random number generator

 MCMC proposal parameters:
 --diffev            (UINT4) relative weight of using differential evolution of the live points as the proposal
                     (DEFAULT = 0, e.g. 0%)
 --freqBinJump       (UINT4) relative weight of using jumps to adjacent frequency bins as a proposal (DEFAULT = 0,
                     e.g. this is not required unless searching over frequency)
 --ensembleStretch   (UINT4) relative weight of the ensemble stretch proposal (DEFAULT = 0, e.g. 0%) [NOTE: this
                     proposal greatly increases the autocorrelation lengths, so in general should be avoided]
 --ensembleWalk      (UINT4) relative weight of the ensemble walk proposal (DEFAULT = 3, e.g. 75%)
 --uniformprop       (UINT4) relative weights of uniform proposal (DEFAULT = 1, e.g. 25%)

 Reduced order quadrature (ROQ) parameters:
 --roq               Set this to use reduced order quadrature to compute the likelihood
 --ntraining         (UINT4) The number of training models used to generate an orthonormal basis of waveform models
 --roq-tolerance     (REAL8) The tolerance used during the basis generation (DEFAULT = 1e-11)
 --enrich-max        (UINT4) The number of times to try and "enrich" the basis set using new training data. The
                     enrichment process stop before this value is reached if three consecutive enrichment steps
                     produce no new bases (DEFAULT = 100)
 --roq-uniform       Set this flag to cause training model parameters for parameters with Gaussian prior
                     distributions to be drawn from a uniform distribution spanning mu +/- 5 sigma. Otherwise, by
                     default parameters are drawn from their given prior distributions
 --output-weights    (CHAR) If this is set then the weights will be output to the (binary) file that is named and the
                     programme will exit. These could be read in later instead of being regenerated. This allows the
                     ROQ to be generated on a machine with a large amount of RAM, whilst the full parameter
                     estimation can run on a machine with less RAM.
 --input-weights     (CHAR) A binary file containing all the weights in a defined format. If this is present then the
                     RQO will not be recalculated

 Signal injection parameters:
 --inject-file       a pulsar parameter (par) file containing the parameters of a signal to be injected. If this is
                     given a signal will be injected
 --inject-output     a filename to which the injected signal will be output if specified
 --fake-data         a list of IFO's for which fake data will be generated e.g. H1,L1 (delimited by commas). Unless
                     the --fake-psd flag is set the power spectral density for the data will be generated from the
                     noise models in LALNoiseModels. For Advanced detectors (e.g Advanced LIGO) prefix the name with
                     an A (e.g. AH1 for an Advanced LIGO detector at Hanford). The noise will be white across the data
                     bandwidth
 --fake-psd          if you want to generate fake data with specific power spectral densities for each detector giving
                     in --fake-data then they should be specified here delimited by commas (e.g. for --fake-data H1,L1
                     then you could use --fake-psd 1e-48,1.5e-48) where values are single-sided PSDs in Hz^-1
 --fake-starts       the start times (in GPS seconds) of the fake data for each detector separated by commas (e.g.
                     910000000,910021000). If not specified these will all default to 900000000
 --fake-lengths      the length of each fake data set (in seconds) for each detector separated by commas. If not
                     specified these will all default to 86400 (i.e. 1 day)
 --fake-dt           the data sample rate (in seconds) for the fake data for each detector. If not specified this will
                     default to 60s
 --scale-snr         give a (multi-detector) SNR value to which you want to scale the injection. This is 1 by default

 Legacy code flags:
 --oldChunks        Set if using fixed chunk sizes for dividing the data as in the old code, rather than the
                    calculating chunks using the change point method
 --source-model     Set if using both 1 and 2 multiples of the frequency and requiring the use of the original source
                    model parameters from Jones, MNRAS, 402 (2010)

 Benchmarking:
 --time-it          Set if wanting to time the various parts of the code. A output file with the "outfile" filename
                    appended with "_timings" will contain the timings
 --sampleprior      (UINT4) Set this to be a number of samples generated from the prior. The nested sampling will not
                    be performed
\end{lstlisting}

\subsection{Examples}\label{app:examples}

Here we show a few real examples of using the code for a variety of situations. In all cases there are a minimum of
three files that must be specified to run the code:
\begin{enumerate}
 \item one (or more) data files containing a complex time series. These will generally be (although do not have to be) the output
 of the heterodyne method described in \citep{2005PhRvD..72j2002D} (and implemented with {\tt lalapps\_heterodyne\_pulsar}), or
 the {\it Spectral Interpolation} method described in \citep{2017CQGra..34a5010D}. Files must be in ascii text format with three, or
 four, whitespace-seperated columns. In either case the first three columns
 specify the data timestamp in GPS seconds, the real part of the data, and the imaginary part of the data, e.g.
 \verb|900000000 1.2564374e-22 -4.5764347e-22|. In the case where a fourth column is present this should give the noise standard
 deviation, and is for use if running with the Gaussian likelihood function. The code will automatically determine if the input
 contains three or four columns. The data does not have to be uniformly sampled and can 
contain gaps. However,
 if searching for a signal for which there could still be some frequency modulation it is useful for the data to have a large
 enough bandwidth to contain the modulation.
 The file can contain comments if the comment lines start with
 a \verb|%| or \verb|#|. Gzipped versions of these files can also be input.
 \item a pulsar parameter file. This should be an ascii {\sc tempo(2)}-style \verb|.par| file containing information on the
 source's parameters, e.g. sky location and frequency, as generated by {\sc tempo}\footnote{http://tempo.sourceforge.net/} or
 {\sc tempo2} \citep{2006MNRAS.369..655H}  from pulsar pulse time-of-arrival observations. An example \verb|.par| file is given below.
 \item a prior distribution file. This should be an ascii file containing information on the prior distributions
 required for any variable parameters that the code needs to sample posterior probability distribtions for. An example
 prior file is given below.
\end{enumerate}

In the examples below we will assume that the LALsuite software package\footnote{\url{https://www.lsc-group.phys.uwm.edu/daswg/projects/lalsuite.html}} has
been installed and that the executable binaries for \lppen and {\tt lalapps\_nest2pos} are in your path (i.e.\ the directory path containing those
executables is set in the list of values in your {\tt PATH} environment variable). The code can automatically find solar system ephemeris and timing
files provided they are in a standard location, although these can also be specified explicitly on the command line.

\subsubsection{An example {\tt .par} file}

The {\tt .par} file input should be the same file that was used when performing the heterodyning (or {\it Spectral Interpolation})
of the data used to produce the input data time series. A {\sc tempo(2)}-style {\tt .par} file could have the following form, e.g.\
for a pulsar in a binary system:
\newsavebox{\Lst}
\begin{lrbox}{\Lst}
\begin{lstlisting}
PSRJ    J0234+5612
RAJ     02:34:12.123485
DECJ    56:12:05.237474
F0      102.764742743786  1  1.2341e-10
F1      -8.854276e-14
PEPOCH  54012.2853
BINARY  BT
ECC     0.023
T0      53424.24435856
OM      12.858534
PB      9.858345
A1      3.474743
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]

The majority of the parameters that can be in a {\tt .par} file are listed in Table~A1 of \citep{2006MNRAS.372.1549E}.
Note that the code does not compute effects of dispersion measure (i.e.\ it assumes observations at infinite frequency),
or atmospheric effects, so it is highly preferable to use a {\tt .par} file for which these parameters have been not
used, or held fixed.

For pulsars in binary systems the code can currently use the following binary system models \citep[see e.g.][for discussion
of some of the models]{1989ApJ...345..434T,2007PhRvD..76d2006P}: {\tt BT}, {\tt BTX},
{\tt BT1P}, {\tt BT2P}, {\tt ELL1}, {\tt DD}, {\tt DDS}, {\tt MSS}, and {\tt T2} (although not all aspects of the
{\tt T2} model are implemented). The code can use the TDB or TCB time systems, with the TCB system being the default if not otherwise
specified (either by supplying the require timing files, as described below, or by setting {\tt UNITS TDB} in the {\tt .par} file).
The code can accept {\tt .par} files calculated using the JPL DE200, DE405, DE414, or DE421 solar system ephemerides, noting
that it only takes into account the motion of the Earth-Moon system and the Sun, but no other solar system bodies.

The {\tt .par} file can also contain a selection of gravitational wave parameters not present in the case of a standard
electromagnetically observed pulsar. A full list of the allowed parameter names for a {\tt .par}, and a prior file described below,
is given in Table~\ref{tab:paramlist}.

\begin{longtable}{l|l}
\caption{A list of parameters allowed in a {\tt .par} file or a prior file. The true-type font versions, in uppercase only,
are what is allowed in the files. The specified units are for the {\tt .par} file, whereas the prior file
requires values in SI units.}\label{tab:paramlist} \\
Parameter & Description \\
\hline
\multicolumn{2}{c}{Gravitational wave parameters} \\
\hline
{\tt H0}, $h_0$      & gravitational wave amplitude for the $l=m=2$ mode in the source model \\
{\tt IOTA}, $\iota$  & pulsar inclination angle to the line-of-sight (rads) \\
{\tt COSIOTA}, $\cos{\iota}$ & cosine of $\iota$ \\
{\tt PSI}, $\psi$    & polarisation angle of the gravitational waves (rads) \\
{\tt PHI0}, $\phi_0$ & rotational phase of the pulsar (rads) \\
{\tt C22}, $C_{22}$  & gravitational wave amplitude for the $l=m=2$ mode in the waveform model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt C21}, $C_{21}$  & gravitational wave amplitude for the $l=2, m=1$ mode in the waveform model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt PHI22}, $\Phi_{22}^C$ & gravitational wave phase for the $l=m=2$ mode in the waveform model (rads) \citep[see][]{2015MNRAS.453.4399P} \\
{\tt PHI21}, $\Phi_{21}^C$ & gravitational wave phase for the $l=2, m=1$ mode in the waveform model (rads) \citep[see][]{2015MNRAS.453.4399P} \\
{\tt Q22}, $Q_{22}$ & $l=m=2$ mass quadrupole moment (kg\,m$^{2}$) \citep[see e.g.][]{2005PhRvL..95u1101O} \\
{\tt HPLUS}, $H_+$ &  gravitational wave amplitude for the $l=m=2$ mode in the source model for the $+$-polarisation \\
{\tt HCROSS}, $H_{\times}$ &  gravitational wave amplitude for the $l=m=2$ mode in the source model for the $\times$-polarisation \\
{\tt I21}, $I_{21}$ & physical gravitational wave amplitude in source model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt I31}, $I_{31}$ & physical gravitational wave amplitude in source model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt LAMBDA}, $\lambda$ & Euler angle in source model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt THETA}, $\theta$ & Euler angle in source model \citep[see][]{2015MNRAS.453.4399P} \\
{\tt COSTHETA}, $\cos{\theta}$ & cosine of $\theta$ \\
\hline
\multicolumn{2}{c}{Signal phase parameters} \\
\hline
{\tt F}$X$, $f_X$ & rotational frequency, and frequency derivatives (starting at 0), (Hz$\,s^{-X}$) \\
{\tt PEPOCH} & the epoch of the frequency \\
\hline
\multicolumn{2}{c}{Signal positional parameters} \\
\hline
{\tt RA}/{\tt RAJ}, $\alpha$ & pulsar right ascension ({\tt hh:mm:ss.s}) \\
{\tt DEC}/{\tt DECJ}, $\delta$ & pulsar declination ({\tt dd:mm:ss.s}) \\
{\tt PMRA} & proper motion in right ascension (mas\,yr$^{-1}$) \\
{\tt PMDEC} & proper motion in declination (mas\,yr$^{-1}$) \\
{\tt POSEPOCH} & the epoch of the sky position (MJD) \\
{\tt EPHEM} & the JPL solar system ephemeris \\
{\tt PX} & pulsar parallax (mas) \\
{\tt DIST} & pulsar distance (kpc) \\
\hline
\multicolumn{2}{c}{Binary system oribital parameters} \\
\hline
{\tt BINARY} & binary system model \citep[see e.g.][and references therein]{1989ApJ...345..434T} \\
{\tt A1}, $a\sin{i}$ & projected semi-major axis (lt-s) \\
{\tt PB}, $P_{\text{b}}$ & binary period (days) \\
{\tt OM}, $\omega_0$ & longitude of periastron (degs) \\
{\tt T0} & time of periastron (MJD) \\
{\tt ECC}, $e$ & oribtal eccentricity \\
{\tt EPS1}, $\varepsilon_1$/$\eta$ & $e\sin{\omega_0}$ for {\tt ELL1} model \citep[see Appendix in][]{2001MNRAS.326..274L} \\
{\tt EPS2}, $\varepsilon_2$/$\kappa$ & $e\cos{\omega_0}$ for {\tt ELL1} model \citep[see Appendix in][]{2001MNRAS.326..274L} \\
{\tt TASC}, $T_{\text{asc}}$ & time of the ascending node for {\tt ELL1} model \citep[see Appendix in][]{2001MNRAS.326..274L} \\
{\tt GAMMA}, $\gamma$ & relativistic gravitational redshift and time dilation term in {\tt BT} model (s) \\
{\tt OMDOT}, $\dot{\omega}_0$ & time derivative of $\omega_0$ (degs\,yr${-1}$) \\
{\tt XDOT} & time derivative of $a\sin{i}$ (lt\,s\,s$^{-1}$ or $10^{-12}$lt-s\,s$^{-1}$ if $|\dot{a\sin{i}}| > 10^{-7}$)  \\
{\tt PBDOT}, $\dot{P}_{\text{b}}$ & time derivative of period ($10^{-12}$ if $|\dot{P_{\text{b}}}| > 10^{-7}$) \\
{\tt EDOT}, $\dot{e}$ & time derivative of eccentricity (s$^{-1}$ or $10^{-12}$\,s$^{-1}$ if $|\dot{e}| > 10^{-7}$) \\
{\tt EPS1DOT}, $\dot{\varepsilon}_1$ & time derivative of $\varepsilon_1$ (s$^{-1}$ or $10^{-12}$\,s$^{-1}$ if $|\dot{\varepsilon_1}| > 10^{-7}$) \\
{\tt EPS2DOT}, $\dot{\varepsilon}_2$ & time derivative of $\varepsilon_2$ (s$^{-1}$ or $10^{-12}$\,s$^{-1}$ if $|\dot{\varepsilon_2}| > 10^{-7}$) \\
{\tt XPBDOT} & time derivative of period minus GR prediction ($10^{-12}$ if $|\dot{P_{\text{b}}}| > 10^{-7}$) \\
{\tt SINI}, $\sin{i}$ & sine of oribital inclination angle \\
{\tt MTOT}, $M$ & total binary system mass (M$_{\odot}$) \\
{\tt M2}, $m_2$ & binary companion mass (M$_{\odot}$) \\
{\tt DR}, $d_r$ & relativistic deformation of the orbit \\
{\tt DTHETA}, $d_{\theta}$ & relativistic deformation of the orbit \\
{\tt SHAPMAX}, $s_x$ & defined as $-\ln{(1-\sin{i})}$ \\
% {\tt KIN}, $i$ & inclination angle (Kopeikin term) (degs) \\
{\tt KOM}, $\Omega$ & longitude of ascending node (Kopeikin term) (degs) \\
{\tt D\_AOP} & Kopeikin term (arcsec$^{-1}$) \citep[see e.g.\ Section~2.7.1 of][]{2006MNRAS.372.1549E} \\
{\tt A1\_}$X$ & projected semi-major axes for multiple orbital components ($X=2,3$ for {\tt BT1P} and {\tt BT2P} models) (lt-s) \\
{\tt PB\_}$X$ & periods for multiple orbital components ($X=2,3$ for {\tt BT1P} and {\tt BT2P} models) (days) \\
{\tt OM\_}$X$ & longitudes of periastron for multiple orbital components ($X=2,3$ for {\tt BT1P} and {\tt BT2P} models) (degs) \\
{\tt T0\_}$X$ & times of periastron for multiple orbital components ($X=2,3$ for {\tt BT1P} and {\tt BT2P} models) (MJD) \\
{\tt ECC\_}$X$ & eccentricities for multiple orbital components ($X=2,3$ for {\tt BT1P} and {\tt BT2P} models) \\
{\tt FB}$X$ & orbital frequencies for multiple components (in {\tt BTX} model) (Hz) \\
{\tt A0}, $A$ & first aberration parameter \citep[see e.g.\ Section~2.7.3 of][]{2006MNRAS.372.1549E} \\
{\tt B0}, $B$ & second aberration parameter \citep[see e.g.\ Section~2.7.3 of][]{2006MNRAS.372.1549E} \\
\hline
\multicolumn{2}{c}{Glitch parameters \citep[see][]{2006MNRAS.369..655H,2013MNRAS.429..688Y}} \\
\hline
{\tt GLEP\_}$X$ & glitch epochs (MJD) \\
{\tt GLPH\_}$X$ & glitch rotational phase offsets (rads) \\
{\tt GLF0\_}$X$ & glitch frequency offsets (Hz) \\
{\tt GLF1\_}$X$ & glitch first frequency derivative offsets (Hz\,s$^{-1}$) \\
{\tt GLF2\_}$X$ & glitch second  frequency derivative offsets (Hz\,s$^{-2}$) \\
{\tt GLF0D\_}$X$ & glitch decaying frequency components (Hz) \\
{\tt GLTD\_}$X$ & glitch time constant for decaying components (s) \\
\hline
\multicolumn{2}{c}{Non-GR parameters} \\
\hline
{\tt CGW}, $c_{\text{gw}}$ & speed of gravitational waves as a fraction of the speed of light \\
\hline
\hline
\end{longtable}


\subsubsection{Example prior file}

The prior functions used by the code are decribed in Section~\ref{sec:priorfuncs}. To implement them in the code requires a prior
file specifying the prior function require for each parameter that will be varied. A an example prior file containing all the
allowed prior types (for descriptive purposed only) is:
\begin{lstlisting}[frame=single]
H0      fermidirac 4.316e-24 9.1625
PHI0    uniform    0.0       3.141593
PSI     gaussian   0.6764    0.16532
A1      loguniform 1e-3      1e6
F0:F1   gmm        2  [[123.4,-1e-9],[123.4,-1.5e-9]] [[[1e-16,1e-18],[1e-18,1e-10]],[[1e-16,1e-18],[1e-18,1e-10]]] [0.5,1]
COSIOTA gmm        2  [[1.5896]]  [[[0.0219]]]  [1.0]  [[1.5519]]  [[[0.0219]]]  [1.0] [-1,1]
\end{lstlisting}
The units required for parameters in a prior file are all SI units, whereas for the {\tt .par} file they often follow a different
convention (see Table~\ref{tab:paramlist}).

Going through each line we have:
\begin{description}
 \item[{\tt{H0}}] this parameter has been assigned a Fermi-Dirac prior (\S\ref{sec:fdprior}) using the {\tt fermidirac} tag, which requires two values: $\sigma$ and $r$.
 \item[{\tt{PHI0}}] this parameter has been assigned a uniform prior (\S\ref{sec:uniformprior}) using the {\tt uniform} tag, which requires two values: a lower limit and an upper limit.
 \item[{\tt{PSI}}] this parameter has been assigned a Gaussian prior (\S\ref{sec:gaussianprior}) using the {\tt gaussian} tag, which requires two values: a mean and a standard deviation.
 \item[{\tt{A1}}] this parameter has been assigned a prior uniform in the logarithm of the parameter (\S\ref{sec:loguniform}) using the {\tt loguniform} tag, which
 required two values: a lower limit and an upper limit on the parameter ({\it not} the logarithm of the parameter).
 \item[{\tt{F0:F1}}] this pair of parameters has been assigned a Gaussian mixture model prior (\S\ref{sec:gmmprior}). This prior can be used for any number of
 parameters if given as a colon seperated list in the prior file. Following the {\tt gmm} assigment, a number gives the number of modes for the model. This is then
 followed by a square-bracketed list of lists, with each mode giving a comma separated main list entry containing a sublist of comma separated means for each parameter 
 (no additional whitespace is allowed in the lists). The list of means is then followed by a similar list of parameter covariance matrices for each mode (again no
 additional whitespace is allowed). This is then followed by a final bracketed list giving the relative weights for each mode (the weights do not have to be
 normalised to unity, as the code will automatically normalise them). If required this can then be followed by pairs of bracketed, comma separted value, for each
 parameter giving their mimumum and maximum allowed ranges. If these are given then they have to be given for all parameters, not just some subset. These are not
 given in this example.
 \item[{\tt{COSIOTA}}] this single parameter has been assigned a Gaussian mixture model prior (\S\ref{sec:gmmprior}). This shows how to input a Gaussian mixture
 mode for a single parameter, and also shows at the end mimumum and maximum ranges for the parameter have also been input.
\end{description}

If parameters in the prior file are specified with the {\tt gaussian} tag then a multivariate Gaussian prior may also be used for them if a correlation matrix
is passed to \lppen (using the {\tt --cor-file} flag) containing correlation coefficients for the required parameters. Only the lower diagonal of the
correlation matrix is required, e.g.\ if we wanted a multivariate prior on $f_0$ and $\dot{f}$ we could have a correlation coefficient file containing:
\begin{lrbox}{\Lst}
\begin{lstlisting}
      F0   F1
F0    1
F1    0.5  1
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
where the whitespace can be tabs of spaces, whilst the prior file contains the means and standard deviations of the parameters as noted above. It is worth noting
that for fully (anti)correlated parameters correlation coefficients of one can lead to numerical issues during matrix inversion. So, in such cases the
(anti)correlation could be reduced to, say, 99.99\%. However, better solutions to such a degeneracy would be to fix one of the correlated values (i.e.\ do not include
it in the prior file) and only search over the other, or finding a non-degenerate re-parameterisation.

\subsubsection{Example 1: single detector, single harmonic, input data}\label{sec:example1}

One of the simplest cases for running the code is on input data from a single detector and at a single frequncy harmonic (in this
case at twice the rotation frequency). Let us assume a search that is just interested in a signal model described by the four parameters
$h_0$, $\phi_0$, $\cos{\iota}$ and $\psi$, and set a prior file, called {\tt prior.txt}, containing
\begin{lrbox}{\Lst}
\begin{lstlisting}
H0      uniform 0 1e-20
PHI0    uniform 0 3.14159265359
PSI     uniform 0 1.57079632679
COSIOTA uniform -1 1
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
Given a pulsar {\tt .par} file, called, for example, {\tt pulsar.par} containing\footnote{For a search that does not include any phase evolution parameters
the only required values in the {\tt .par} file are the right ascension and declination, but in general the file passed to the code should be the one used
to perform the heterodyning that produced the input data file.}
\begin{lrbox}{\Lst}
\begin{lstlisting}
PSRJ   J1234+5601
RAJ    12:24:00.00
DECJ   56:01:00.00
F0     100.01
F1     -1.1e-10
PEPOCH 56789
EPHEM  DE405
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
and assuming the input data (from the LIGO Hanford detector, H1, in this case) is in a file called {\tt data\_H1.txt}, then one would run:
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --detectors H1 --input-files data_H1.txt --par-file pulsar.par --prior-file prior.txt --outfile nest_H1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1
\end{lstlisting}
where we have set an output HDF5-format file called {\tt nest\_H1.hdf} in which the nested samples will be output. This setup has used 1024 nested sampling
live points and a tolerance of 0.1 for stopping the code. The {\tt --Nmcmcinitial 0} flag tells the code that the initial live points drawn do not have to
be resampled.\footnote{This option is present for cases when the initial live points may not be easily sampled from the prior distributions, and therefore
an MCMC procedure is required to try and evolve them to be from the actual prior. However, for all our priors there are simple ways to draw the initial
live points from the prior, so this resampling is not required, and this input argument can be set to zero.} In this case the solar system ephemeris files
will be found automatically. If the {\tt EPHEM} or {\tt UNITS} parameters are not explicitly set in the {\tt .par} file then these will default to the
DE405 ephemeris and the TCB time system. The progress of the above code can be monitored by including the {\tt --verbose} flag, and watching how the
reported {\tt dZ} value approaches the required tolerance.

Along with the file of nested samples two additional files called {\tt nest\_H1\_SNR} and {\tt nest\_H1\_Znoise} will be output. The former contains the
recovered optimal SNR for the maximum likelihood sample. The later contains the null likelihood, or noise, evidence for the data, described in
\S\ref{sec:nulllike}. The noise evidence is also contained in the {\tt nest\_H1.hdf} file, but this additional file is useful in cases when multiple
harmonics are used as it will contain noise evidences for individual harmonic datastreams, as well as that for the multiple combined streams.

The nested sample file can be converted to a file containing posterior samples, called, say, {\tt post\_H1.hdf}, using:
\begin{lrbox}{\Lst}
\begin{lstlisting}
$ lalapps_nest2pos -p post_H1.hdf nest_H1.hdf
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
where the {\tt -p} flag give the name of the posterior output file. If the above use of \lppen had been run more than once on the same data and prior file,
with output names given by e.g.\ {\tt nest\_H1\_01.hdf}...{\tt nest\_H1\_$N$.hdf}, then all these could be listed as input to {\tt lalapps\_nest2pos} to
combined all the samples and evidence estimates. As well as the posterior samples, this file also contains (as did the {\tt nest\_H1.hdf}),
the signal model evidence, the noise model evidence, and the information gain (amongst other things).

The posterior samples, and noise and signal model (natural logarithm) evidences, can be extracted using a python function within {\tt lalapps}, via
\begin{lrbox}{\Lst}
\begin{lstlisting}
$ python
>>> from lalapps import pulsarpputils as pppu
>>> postsamples, sigevidence, noiseevidence = pppu.pulsar_nest_to_posterior('post_H1.hdf')
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
The {\tt postsamples} variable is an object from which samples from different parameters can be extracted, and plotted as a marginalised posterior
distribution, e.g.\
\begin{lrbox}{\Lst}
\begin{lstlisting}
>>> from matplotlib import pyplot as pl
>>> # plot the posterior samples for the H0 parameter
>>> pl.hist(postsamples['H0'].samples, bins=20, normed=True, histtype='stepfilled')
>>> pl.xlabel('$h_0$')
>>> pl.ylabel('Posterior Probability Density')
>>> pl.show()
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
where here, for the $h_0$ parameter it is contained in {\tt postsamples} as the fully uppercase {\tt 'H0'} value. 

Alternatives to extract the (natural logarithm) evidence values are using the {\tt h5py} python module, or HDF5 command line utilities. For the former one could
use, e.g.\
\begin{lrbox}{\Lst}
\begin{lstlisting}
>>> import h5py
>>> hdf = h5py.File('post_H1.hdf', 'r')
>>> a = hdf['lalinference']['lalinference_nest']
>>> sigevidence = a.attrs['log_evidence']
>>> noiseevidence = a.attrs['log_noise_evidence']
>>> information = a.attrs['information_nats']
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
or for the latter one could use, e.g.\
\begin{lrbox}{\Lst}
\begin{lstlisting}
$ h5ls -v post_H1.hdf/lalinference/ | grep -A2 evidence
    Attribute: log_evidence scalar
        Type:      native double
        Data:  141816
--
    Attribute: log_noise_evidence scalar
        Type:      native double
        Data:  141822
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
However, note that in this latter example the evidence values are truncated to integer values.

\subsubsection{Example 2: single detector, single harmonic, simulated data}

As well as taking real data as an input the code can simulate Gaussian noise, and/or create and add a simulated signal to the data. To create
a signal to inject into the data requires a {\tt .par} file for the signal parameters. This can be the same, or different, to the file input
using the {\tt --par-file} flag, but to produce a non-zero signal it must contain at least a \gw amplitude parameter (any parameters not
included will be assumed to be zero). Any differences between the phase evolution parameters between the two files will be incorporated into the
signal via Equation~\ref{eq:deltaphi}. Given an injection par file, called, say, {\tt injection.par}, containing
\begin{lrbox}{\Lst}
\begin{lstlisting}
PSRJ    J1234+5601
RAJ     12:24:00.00
DECJ    56:01:00.00
F0      100.01
F1      -1.1e-10
PEPOCH  56789
EPHEM   DE405
H0      1e-25
COSIOTA -0.43
PHI0    0.6
PSI     1.2
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
(which we see is the same as in \S\ref{sec:example1}, but with \gw amplitude parameters), one would run the following (assuming various other
names are the same as in \S\ref{sec:example1})
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --fake-data H1 --inject-file injection.par --scale-snr 10 --par-file pulsar.par --prior-file prior.txt --outfile nest_H1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1
\end{lstlisting}
Here, rather than inputting a real data file, the {\tt --fake-data} flag has been used to specify fake data from the LIGO Hanford detector, where the
design sensitivity \citep{SRD}\footnote{\url{https://labcit.ligo.caltech.edu/~jzweizig/distribution/LSC_Data/}} power spectral density noise curve
would be used to set the Gaussian noise level for an initial LIGO detector at the appropriate \gw frequency (twice the value of {\tt F0} given in the {\tt .par}
file for the standard search).\footnote{Other
named detectors that can be provided are L1 for the LIGO Livingston detector, G1 for the GEO600 detector \citep[from Table~IV of][]{2001PhRvD..63d4023D},
V1 for the initial Virgo detector, and T1 for the TAMA300 detector \citep[from Table~IV of][]{2001PhRvD..63d4023D}. For the two LIGO detectors
\citep{aLIGOSRD} and Virgo \citep[see Equation~6 of][]{2012arXiv1202.4031M}, design curve noise levels for their Advanced configurations can be obtained
by prefixing the names with an `A'.} Setting the noise level from the design sensitivity or a given detector can be overridden by also using the
{\tt --fake-psd} flag to input the required single sided
power spectral density value. The simulated data will by default start at a GPS time of 900000000, be sampled at a rate of once per minute, and last for
one solar day. However, each of these can be set with the appropriate flags: {\tt --fake-starts}, {\tt --fake-lengths}, and {\tt --fake-dt} respectively.
In this example a value is also set for {\tt --scale-snr}, which means that after the creating of a signal with parameters as given in the {\tt injection.par}
file, it will be re-scaled so that it has the given SNR - in this case a value of 10. This enables signals to be injected with a known SNR without needing to
know the noise level a priori. If the {\tt --scale-snr} flag is not set, or has a value of zero, then no re-scaling takes place. In this case the output
{\tt nest\_H1\_SNR} file would also contain the signal's injected SNR and the recovered SNR, e.g.\
\begin{lrbox}{\Lst}
\begin{lstlisting}
$ cat nest_H1_SNR
# Injected SNR
H1	2.000	2.642255e+01	1.000000e+01
# Recovered SNR
H1	2.000	1.092211e+01
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
where, after the detector name the harmonic frequency scaling factor is given, and for the injected signal the two SNR values are the pre-scaled value
and the actually injected value after rescaling via {\tt --scale-snr} value.

A simulated signal can also be injected into real data in the same way.

\subsubsection{Example 3: multiple detectors, single harmonic}

Running with multiple detectors requires a simple change to the example given in \S\ref{sec:example1}. Given two input files, e.g.\ {\tt data\_H1.txt}
and {\tt data\_L1.txt}, for the two LIGO detectors H1 and L1, one would simply use, e.g.\
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --detectors H1,L1 --input-files data_H1.txt,data_L1.txt --par-file pulsar.par --prior-file prior.txt --outfile nest_H1L1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1
\end{lstlisting}
where the order of listing the detectors with the {\tt --detectors} flag should match the order of listing the data files with the {\tt --input-files} flag.
No whitespace is allowed between detector values or input file values, and the must be seperated by a comma. In this case the output {\tt nest\_H1L1\_SNR} file
will contain the individual detector recovered SNRs and the coherent SNR, whilst the {\tt nest\_H1L1\_Znoise} file will contain both the individual detector
noise model evidences and the combined noise model evidence.

\subsubsection{Example 4: multiple detectors, two harmonics}

It is simple to extend the analysis to include the two harmonics from the $l=m=2$ mode (with a \gw frequency at twice the rotation rate) and the $l=2$, $m=1$
harmonic (with a \gw frequency at the rotation rate). To search at these two harmonics requires that the parameters searched over are either the signal, or
waveform, parameters given in \citet{2015MNRAS.453.4399P}. Using the (simpler and non-degenerate) waveform parameters $C_{21}$, $C_{22}$, $\Phi_{21}^C$ and
$\Phi_{22}^C$, from Equations~\ref{eq:hf} and \ref{eq:h2f}, could lead to the following ({\tt prior.txt}) prior file
\begin{lrbox}{\Lst}
\begin{lstlisting}
C22     uniform 0 1e-20
C21     uniform 0 1e-20
PHI22   uniform 0 6.28318530718
PHI21   uniform 0 6.28318530718
PSI     uniform 0 1.57079632679
COSIOTA uniform -1 1
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
Assuming that for each detector (H1 and L1) the data has been heterodyned at both harmonics, leading to files {\tt data\_H1\_1f.txt}, {\tt data\_H1\_2f.txt},
{\tt data\_L1\_1f.txt}, {\tt data\_L1\_2f.txt}, where {\tt 1f} and {\tt 2f} note the harmonic rotation frequency scaling, then one would use
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --detectors H1,L1 --harmonics 1,2 --input-files data_H1_1f.txt,data_H1_2f,data_L1_1f.txt,data_L1_2f.txt --par-file pulsar.par --prior-file prior.txt --outfile nest_H1L1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1
\end{lstlisting}
Here the ordering of the input files is important, with the files for each harmonic for a given detector listed together, and in the same order as given by the
{\tt --harmonics} flag.

\subsubsection{Example 4: single detectors, additional parameters}

Finally, we show an example when searching over additional phase evolution parameters. We show two options for this: the first is using the standard
model and likelihood method, and the second performs the same search, but sped-up by using the ROQ likelihood. If one were searching over frequency and
frequency derivative, $f_0$ and $\dot{f}$, then an example {\tt .par} file ({\tt pulsar.par}) could be
\begin{lrbox}{\Lst}
\begin{lstlisting}
PSRJ   J1234+5601
RAJ    12:24:00.00
DECJ   56:01:00.00
F0     100.01
F1     -1.1e-10
PEPOCH 54660
EPHEM  DE405
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
with a prior file ({\tt prior.txt}) containing
\begin{lrbox}{\Lst}
\begin{lstlisting}
H0      uniform 0 1e-20
PHI0    uniform 0 3.14159265359
PSI     uniform 0 1.57079632679
COSIOTA uniform -1 1
F0      gaussian 100.01   1e-5
F1      gaussian -1.1e-10 2e-11
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
Note that the frequency and frequency derivative values in the prior file are for the rotation frequency, so if searching for the standard $l=m=2$
harmonic then the actual frequencies and derivatives (and in this case their standard deviation) covered will be twice these values. This would also
be the case for any other form of the prior. As, in this example, the {\tt F0} and {\tt F1} values have be assigned Gaussian priors, if they have a
known correlation then a correlation coefficient file ({\tt pulsar.cor}) could also be set, e.g.\
\begin{lrbox}{\Lst}
\begin{lstlisting}
    F0  F1
F0  1.0
F1  0.7 1.0
\end{lstlisting}
\end{lrbox}
\\[5pt] \indent \fbox{\usebox{\Lst}} \\[5pt]
However, if this is not provided, then the parameters will be assumed to a priori be uncorrelated.

If running without ROQ, for a data from a single detector, H1 ({\tt data\_H1.txt}), the following commands could be used
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --detectors H1 --input-files data_H1.txt --par-file pulsar.par --prior-file prior.txt --cor-file pulsar.cor --outfile nest_H1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1
\end{lstlisting}

To run with ROQ enabled, in the simplest case, requires the user to set a number of training waveforms and tolerance to use the produce a reduced order
model.\footnote{For now we do not attempt to explain these parameters, which we are leaving to a future publication, other than to say that for broader
parameter space searches (or searches over frequency derivates for which the epoch is further from the data epoch) more training waveforms are required
for a given tolerance. For a fixed tolerance if the parameter space is too broad more templates may be required than are computational feasible (due to e.g.\
memory constraints) to use.} In this example we will use 2500 training waveforms, and a tolerance of $5\ee{-12}$, and assume data that starts at the same
epoch as given in the {\tt .par} file. The following commands could be used
\begin{lstlisting}[frame=single]
$ lalapps_pulsar_parameter_estimation_nested --detectors H1 --input-files data_H1.txt --par-file pulsar.par --prior-file prior.txt --cor-file pulsar.cor --outfile nest_H1.hdf --Nmcmcinitial 0 --Nlive 1024 --tolerance 0.1 --roq --roq-tolerance 5e-12 --ntraining 2500
\end{lstlisting}

In this example, for a single run on a random realisation of Gaussian noise lasting one day and sampled at a rate of one per minute, we find that the ROQ
version runs about 1.6 times faster. Within the given tolerance it reduces the prior parameter space to 32 orthogonal waveform templates, thus reducing the
the model and likelihood evaluations from using 1440 to 32 points. Due to various overheads the speed-up we see between the ROQ and regular run is only a factor
of $\sim 1.8$, rather than the $1440/32 = 45$ factor that might be hoped for. However, more impressive speed-up can be observed for longer data sets. It should be
noted that this observed speed-up is not a general rule, but is specific to the data and set up we used, but similar speed-ups for similar set ups would not be
unexpected. We also find that the likelihoods produced by the ROQ method agree very well with that produced using the full likelihood evaluation, with the
maximum-likelihood-template likelihoods agreeing to within $6\ee{-10}\%$.

\subsection{The pipeline}

The process of performing searches for known pulsars using does not just used \lppen. It actually requires a whole pipeline of code to: gather the \gw detector
data and operational segments (``science mode'');  pre-processing the raw data via heterodyning (or spectral interpolation) to give the complex down-sampled
time series; setting up the required prior distribution files; passing the data and priors to \lppen; converting the output nested samples into posterior samples;
and, finally, displaying those results (including odds values) in a useful fashion, e.g.\ on a webpage. This process can be performed manually in a step by step
manner, but there also exists a pipeline script called {\tt lalapps\_knope} that gathers together all these operations in a way that can be run on a computer
cluster running the HTCondor\footnote{\url{https://research.cs.wisc.edu/htcondor/}} job management system.

To run this pipeline requires just a single configuration file to be written in the {\tt INI}\footnote{\url{https://en.wikipedia.org/wiki/INI_file}} format. An
example configuration file is given below containing comments on the necessary input fields:
\begin{lstlisting}[frame=single]
# Example configuration file for the full known pulsar search pipeline

; general inputs for the whole analysis
[analysis]
# a list of the inteferometers to analyse (REQUIRED)
ifos = ['H1', 'L1']

# a GPS start time (if a single value is set then this is used for all detectors), or a dictionary of GPS start times for the analysis; one for each detector (e.g. {'H1': 1129136415, 'L1': 1129137415})
starttime = 1129136415

# a GPS end time (if a single value is set then this is used for all detectors), or a dictionary of GPS end times for the analysis; one for each detector (e.g. {'H1': 1129136415, 'L1': 1129137415})
endtime = 1129284015

# choose whether to use lalapps_heterodyne_pulsar (heterodyne) or lalapps_SplInter (splinter) (value is case insensitive)
preprocessing_engine = heterodyne

# a flag to set if just wanting to do the data processing (e.g. heterodyne or splinter) and not parameter estimation
preprocessing_only = False

# a flag to set if just wanting to do the postprocessing (parameter estimation and webpage page creation)
postprocessing_only = False

# if just doing the postprocessing (i.e. 'postprocessing_only = True') a pickled version of the class used for the
# preprocessing (or entire previous run is required) to obtain information on the pre-processed data
preprocessed_pickle_object =

# flag to set whether to run the analysis for individual detectors only (default is to run on individual detectors AND coherently with all detectors)
incoherent_only = False

# flag to set whether to only run the coherent multi-detector analysis
coherent_only = False

# set the number of background odds ratio studies when doing parameter estimation
num_background = 0

# a list of multiplicative factors of the pulsar's rotation frequency to analyse (e.g. [1., 2.] for analysing both the 1f and 2f modes)
# This can be a list if either 1 or 2 values, but if it is a list of two values they can currently only [1., 2.] (or [2., 1.]),
# whereas if there is only one value it can take any positive number.
freq_factors = [2.0]

# the path for timing and solar system ephemeris file
ephem_path = /usr/share/lalpulsar

# the directory in which the DAGs are created and run from
run_dir = /home/user/analysis/dags

# the name of the DAG file to create (if not set this will be generated automatically)
dag_name =

# set this flag to automatically submit the Condor DAG created by the script
submit_dag = True

# this flag sets whether running in autonomous mode
# If running in autonomous mode then information on the current state of the run for each pulsar must be kept
# (e.g. a json file must be created for each pulsar containing the end time that has currently been run until,
# it will also contain the previously used segment list as cache file). If no file is found to exist for a
# particular pulsar, e.g. that pulsar has newly been added to the pulsar directory, then it will start from
# scratch for that pulsar (based on the start time in this file). The script (run e.g. with cron once per week)
# that uses this file for the automation should update the endtime on each run.
# A script will be required to produce the the cache files for each pulsar.
autonomous = True

# the initial start time of any autonomous run (as starttime will be updated each time the code is run)
autonomous_initial_start =

# a base directory (for each detector) for preprocessing outputs (structure for the parameter estimation is still required).
# Within each the following structure structure is assumed:
# -> base_dir/PSRname
#           |       '-> /segments.txt (science segments file for that pulsar)
#           |       '-> /data (directory for processed data files)
#           |               '-> /coarse (directory for coarse heterodyned data)
#           |               |         '-> /freqfactor (directory for heterodyne at freq factor times rotation frequency - if required)
#           |               '-> /fine (directory for fine heterodyned data)
#           |               |       '-> /freqfactor (directory for heterodyne at rotation frequency - if required)
#           |               '-> /splinter (directory for spectrally interpolated data)
#           |                           '-> /freqfactor (directory for heterodyne at rotation frequency - if required)
#           '-> /splinter (a directory to output files from splinter before moving them into the above structure)
#           '-> /cache.lcf (a general frame/SFT cache file used by all pulsar if their directory does not containing there own cache)
preprocessing_base_dir = {'H1': '/home/username/analysis/H1', 'L1': '/home/username/analysis/L1'}

# path to directory containing pulsar parameter (.par) files, or an individual parameter file
# (once the analysis script has been run at least once each .par file will have an associated file (.mod_parfilename) with
# it modification time - if the file is updated, and therefore has a different modification time, then
# the full analysis will be re-run for that pulsar)
pulsar_param_dir = /home/username/analysis/pulsar

# path to log files
log_dir = /home/username/analysis/log

# set to true if running on software/hardware injections
injections = False

# file to output a pickled version of the KnownPulsarPipelineDAG class
pickle_file = /home/username/analysis/run.p

# email address for job completion notication (if no email is given the no notications will be sent)
email =

; Condor information
[condor]
# Condor accounting group
accounting_group =

# Condor accounting group user
accounting_group_user = user.name

# the data find executable (e.g. /usr/bin/gw_data_find), or a dictionary of pre-found cache files (one entry for each detector) if not wanting to use gw_data_find e.g. {'H1': '/home/username/analysis/H1cache.txt'}
datafind = /usr/bin/gw_data_find

; inputs for running a data find job (NOTE: this can be used to search for frame if using the heterodyne, or SFTs if using spectral interpolation)
[datafind]

# a dictionary of frame types to be returned; one for each detector
type = {'H1': 'H1_HOFT_C00', 'L1': 'L1_HOFT_C00'}

# a string to match in the URL paths returned
match = localhost

; Placeholder for information about Max's pulsar database (this could be used instead of requiring local copies of .par files)
[pulsar_database]

; inputs for running a science segment finding job
[segmentfind]
# path to segment database query script, or a dictionary of pre-found segment files (one entry for each detector) if not wanting to use segment finding script e.g. {'H1': '/home/username/analysis/H1segments.txt'}
segfind = /usr/bin/ligolw_segment_query_dqsegdb

# path to ligolw_print
ligolw_print = /usr/bin/ligolw_print

# URL of segment database server
server = https://segments.ligo.org

# a dictionary of the required segment types
segmenttype = {'H1': 'H1:DMT-ANALYSIS_READY:1', 'L1': 'L1:DMT-ANALYSIS_READY:1'}

; inputs for running the lalapps_heterodyne_pulsar code
[heterodyne]
# condor universe
universe = vanilla

# path to lalapps_heterodyne_pulsar
heterodyne_exec = /usr/bin/lalapps_heterodyne_pulsar

# path to directory containing pulsar parameter file (.par) updates, or an individual parameter file
# pulsar_update_dir = /home/username/analysis/pulsar_update # DONT USE FINE HETERODYNE UPDATES - JUST REDO WHOLE HETERODYNE SO THAT THERE AREN'T MULTIPLE PAR FILES/HETERODYNE FILES

# low-pass filter (9th order Butterworth) knee frequency
filter_knee = 0.25

# the frame data sample rate (for the coarse heterodyne)
coarse_sample_rate = 16384

# the re-sampling rate for the coarse heterodyne
coarse_resample_rate = 1

# a dictionary of frame channel names; one for each detector
channels = {'H1': 'H1:GDS-CALIB_STRAIN', 'L1': 'L1:GDS-CALIB_STRAIN'}

# the fine heterodyne re-sampling rate (the sample rate is taken from coarse_resample_rate)
fine_resample_rate = 1/60

# the standard deviation threshold for removing outliers
stddev_thresh = 3.5

# set to output the coarse heterodyne data in binary files (if true then a binary input will be assumed for the fine heterodyne)
binary_output = True

# gzip the coarse output files rather than outputting as binary
gzip_coarse_output = False

# gzip the fine output files
gzip_fine_output = True

; inputs for running the lalapps_SplInter code
[splinter]
# condor universe
universe = vanilla

# path to SplInter executable
splinter_exec = /usr/bin/lalapps_SplInter

# list with the start and end frequency ranges for the SFTs
freq_range = [30., 2000.]

# the standard deviation threshold for removing outliers
stddev_thresh = 3.5

# the bandwidth (Hz) around the signal frequency to use in interpolation
bandwidth = 0.3 # this is the default value from the code

# minimum length (seconds) of science segments to use
min_seg_length = 1800 # this is the default value (half an hour) from the code

; inputs for running the parameter estimation code lalapps_pulsar_parameter_estimation_nested
[pe]
# condor universe
universe = vanilla

# path to the parameter estimation executable
pe_exec = /usr/bin/lalapps_pulsar_parameter_estimation_nested

# the base output directory for the nested samples (directories for each detector/joint analysis will be created)
pe_output_dir = /home/username/analyses/nested_samples

# a pre-made prior file for the analysis (if this is not set then the prior file will be generated for each source based in the par file and/or pre-processed data) - this has priority over any other options in this configuration file
premade_prior_file =

# a set of prior options in dictionary form e.g.
# prior_options = {'H0': {'priortype': 'uniform', 'ranges': [0., 1e-22]}, 'PHI0': {'priortype': 'uniform', 'ranges': [0., 3.14]}}
prior_options =

# if 'derive_amplitude_prior' is true (and the 'premade_prior_file' is not set) then amplitude priors will be derived
# from the heterodyned/spectrally interpolated data based on the either previous upper limits or those
# estimated from ASDs of previous runs.
# The 'amplitude_prior_type' can also be set to either 'fermidirac' (default) or 'uniform'. All other parameters
# will have their ranges taken from 'predefined_prior_options'.
derive_amplitude_prior = True

amplitude_prior_scale = 5

amplitude_prior_type = 'fermidirac'

amplitude_prior_model_type = 'waveform'

# a JSON file with pulsar name keys associated with previous posterior samples files for use as priors in current analysis
previous_posteriors_file = path_to_file_of_previous_posterior_files

# a JSON file with amplitude upper limits from previous runs
amplitude_prior_file = path_to_file_of_previous_upper_limits

# a file, or dictionary or files, containing paths to amplitude spectral density files
amplitude_prior_asds =

# a value, or dictionary of values, containing the observation times (in days) for use with the above ASD files
amplitude_prior_obstimes =

# go through the pulsar parameter file and use the errors to set Gaussian priors in the prior file (also create a correlation coefficient file for these, setting everything to be uncorrelated except the extremely highly correlated binary parameters)
use_parameter_errors = False

# the number of parallel runs for a given
n_runs = 5

# the number of live points for each run
n_live = 2048

# the number of MCMC samples for each nested sample update (if not set this will be automatically calculated)
n_mcmc =

# the number of MCMC samples for initial shuffling of the prior points (shouldn't be needed for pulsar code)
n_mcmc_initial =

# the tolerance (stopping criterion) for the runs
tolerance = 0.1

# a random seed for the RNG (if not set then this will default to it's standard method)
random_seed =

# flag to set whether running with non-GR parameterisation
non_gr = False

# flag to say whether to use the 'waveform' or 'source' parameterisation (defaults to 'waveform')
model_type = 'waveform'

# flag to set whether using a Gaussian likelihood, or the default Student's t-likelihood (if using Splinter for the pre-processing engine then a Gaussian likelihood will automatically be used, and override anything set here)
gaussian_like = False

# flag to set whether the model under consideration is a biaxial model
biaxial = False

; placeholder tags to remind me to implement marginalisation over phase and amplitude calibration uncertainties (for each detector independently)
; cal_marg_amp = {'H1': 10., 'L1': 12.} # 1-sigma percentage amplitude uncertainty
; cal_marg_phase = {'H1': 0.2, 'L1': 0.2} # 1-sigma phase uncertainty (rads)

# path to lalapps_nest2pos for nested sample -> posterior conversion
n2p_exec = /usr/bin/lalapps_nest2pos

# the base output directory for posteriors
n2p_output_dir = /home/username/analyses/posterior_samples

## information for background runs
# the number of live points for background analyses
n_live_background = 1024

# the number of of parallel runs for each
n_runs_background = 2

# the base output directory for the background nested samples (directories for each detector/joint analysis will be created)
pe_output_dir_background = /home/username/analyses/background/nested_samples

# the base output directory for the background posteriors
n2p_output_dir_background = /home/username/analyses/background/posterior_samples

# flag to set whether to clean (i.e. remove) all the nested sample files (keeping the posteriors)
clean_nest_samples = False

# set to true if wanting the output to use the l=m=2 gravitational wave phase as the initial phase, rather than the default rotational phase
use_gw_phase = False

# flags for use of Reduced Order Quadrature (ROQ)
# Any generated ROQ interpolant files will be placed in structure of the pe_output_dir
use_roq = False

# set the number of training sets for using the in reduced basis and interpolant generation
roq_ntraining = 2500

# set the maximum data chunk length for when using ROQ
roq_chunkmax = 1440

# set the tolerance to producing the ROQ bases
roq_tolerance = 5e-12

# set if wanting the bases produced over a uniform parameter space even for (phase) parameters with Gaussian priors
roq_uniform = False

; inputs for creating results pages
[results_page]
# condor universe
universe = local

# results page (Condor) log directory
log_dir = /usr1/username/logs

# results page creation executable
results_exec = /usr/bin/lalapps_knope_result_page.py

# results collation executable
collate_exec = /usr/bin/lalapps_knope_collate_results.py

# the output base web directory for the results
web_dir = /home/username/public_html/results

# the equivalent output base URL for the above path
base_url = https://myurl/~username/results

# the upper limit credible interval to use (default to 95%)
upper_limit = 95

# value on which to sort the results table
sort_value = name

# direction on which to sort the results table
sort_direction = ascending

# list upper limits to show in the results table
results = ['h0ul', 'ell', 'sdrat', 'q22', 'bsn']

# list of source values to output
parameters = ['f0rot', 'f1rot', 'ra', 'dec', 'dist', 'sdlim']

# set whether to show posterior plots for all parameters
show_all_posteriors = False

# set whether to subtract the true/heterodyned value from any phase parameters in a search for plotting
subtract_truths = False

# set whether to show the priors on the 1D posterior plots
show_priors = True

# set whether to copy par file, prior files, heterodyne files, and posterior files into results page directory
# (useful on e.g. ARCCA where scratch space files get removed after 60 days)
copy_all_files = True
\end{lstlisting}

Unless specified as otherwise within a {\tt .par} file the pipeline assumes the use of the TCB timing convention (as is the default for TEMPO2), and the DE405
solar system ephemeris.


